{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid Spread and Movement\n",
    "\n",
    "> **Authors**\n",
    "- [Paul Schrimpf *UBC*](https://economics.ubc.ca/faculty-and-staff/paul-schrimpf/)\n",
    "\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- [Data Visualization: Rules and Guidelines](visualization_rules.ipynb)  \n",
    "- [Mapping in Python](maps.ipynb)  \n",
    "- [Regression](regression.ipynb)  \n",
    "- [Visualizing Corona Virus](covid-trends.ipynb)  \n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Covid Spread and Movement](#Covid-Spread-and-Movement)  \n",
    "  - [Introduction](#Introduction)  \n",
    "  - [Data](#Data)  \n",
    "  - [Mapping](#Mapping)  \n",
    "  - [Relationship between mobility and cases](#Relationship-between-mobility-and-cases)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Uncomment following line to install on colab\n",
    "#! pip install qeds fiona geopandas xgboost gensim folium pyLDAvis descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection, preprocessing\n",
    ")\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "# activate plot theme\n",
    "import qeds\n",
    "qeds.themes.mpl_style();\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case and death data\n",
    "\n",
    "We will use case and death numbers by county from JHU CSSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv('https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv?raw=true')\n",
    "deaths = pd.read_csv('https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv?raw=true')\n",
    "ids = [\"UID\",\"iso2\",\"iso3\",\"code3\",\"FIPS\",\"Admin2\",\"Province_State\",\"Country_Region\", \"Lat\", \"Long_\", \"Combined_Key\"]\n",
    "\n",
    "confirmed=confirmed.melt(id_vars=ids, var_name=\"Date\", value_name=\"cases\")\n",
    "deaths=deaths.melt(id_vars=ids + [\"Population\"],var_name=\"Date\", value_name=\"deaths\")\n",
    "covid = pd.merge(confirmed, deaths, on=ids + [\"Date\"], how='outer')\n",
    "covid[\"Date\"] = pd.to_datetime(covid[\"Date\"])\n",
    "covid[\"FIPS\"] = covid[\"FIPS\"].map(lambda x : -1 if np.isnan(x) else int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlaceIQ movement data\n",
    "\n",
    "Code to download PlaceIQ data on movement from\n",
    "[https://github.com/COVIDExposureIndices/COVIDExposureIndices](https://github.com/COVIDExposureIndices/COVIDExposureIndices)\n",
    "Each day of data uses about 6MB of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datadir = './lex_data'\n",
    "if not os.path.isdir(datadir):\n",
    "    os.mkdir(datadir)\n",
    "\n",
    "# download data if needed\n",
    "start = datetime.date(2020,1,20)\n",
    "end = datetime.date.today()\n",
    "def downloadlex(dates) :\n",
    "    for day in dates :\n",
    "        filename = 'county_lex_' + day.strftime(\"%Y-%m-%d\") + '.csv.gz'\n",
    "        lfile = datadir+'/'+filename\n",
    "        if not os.path.isfile(lfile) :\n",
    "            try :\n",
    "                url = 'https://github.com/COVIDExposureIndices/COVIDExposureIndices/blob/master/lex_data/' + filename + '?raw=true'\n",
    "                r = requests.get(url)\n",
    "                if r.status_code == 200 :\n",
    "                    with open(lfile, 'wb') as f:\n",
    "                        f.write(r.content)\n",
    "                else :\n",
    "                    print(filename + f\" returned {r.status_code}\")\n",
    "            except :\n",
    "                print(\"Failed to download \" + filename)\n",
    "                None\n",
    "    None\n",
    "\n",
    "# read data into memory\n",
    "def loadlexdata(dates) :\n",
    "    dflist = list()\n",
    "    for day in dates :\n",
    "        print(f\"working on {day}\")\n",
    "        filename = datadir+'/county_lex_' + day.strftime(\"%Y-%m-%d\") + '.csv.gz'\n",
    "        if os.path.isfile(filename):\n",
    "            df = pd.read_csv(filename, compression='gzip', header=0)\n",
    "            df[\"date\"] = day\n",
    "            df = df.melt(id_vars=['COUNTY_PRE','date'], var_name='COUNTY', value_name='LEX')\n",
    "            df[\"COUNTY\"] = df[\"COUNTY\"].astype(int)\n",
    "            dflist.append(df)\n",
    "    lexdf = pd.DataFrame().append(dflist)\n",
    "    lexdf.sort_values('date', inplace=True)\n",
    "    return(lexdf)\n",
    "\n",
    "# Just load in one days of data\n",
    "downloadlex([start])\n",
    "lex = loadlexdata([start])\n",
    "lex.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the size of the location data. We only loaded the one oldest\n",
    "day of data. If you try running this code on the all days until today\n",
    "we will need about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "155*(datetime.date.today()-start).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB of memory. To actually analyze the data, it will be useful to have\n",
    "considerably more memory. When faced with such a situation, the best\n",
    "option is usually to simply find a machine with enough memory. The\n",
    "extra programming time that it will take to deal with memory\n",
    "constraints is usually far more costly than buying or renting a larger\n",
    "server.\n",
    "\n",
    "Nonethless, let’s suppose we cannot use a server with more memory for\n",
    "some reason. There are a number of packages and frameworks for dealing\n",
    "with data that cannot fit into RAM. A simple approach that will work\n",
    "for our purposes, is to just operate on each day of data, aggregate to\n",
    "a smaller dataset of what we need, and then combine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement Index\n",
    "\n",
    "The movement data should have number of counties squared times number\n",
    "of days of observations. The main variable is “LEX.”  On each day and\n",
    "for each pair of countains, “LEX” is the share of devices in county\n",
    "“COUNTY” on “date” that were in county “COUNTY_PRE” anytime in the\n",
    "past 14 days (not including ‘date’). Rather than keeping all roughly\n",
    "2000 times 2000 of these values for every day, let’s just keep summary measures.\n",
    "\n",
    "In particular, we will keep “own_lex” which is the “LEX” for “COUNTY”\n",
    "and “COUNTY_PRE” being the same. One minus “own_lex” is then the\n",
    "portion of devices in a county on a given data, that were **not** in\n",
    "the county at all in the past 14 days. In other words, 1-“own_lex” is\n",
    "the portion of devices in a county that are showing there for the time\n",
    "in two weeks.\n",
    "\n",
    "The other measure that we will keep is\n",
    "\n",
    "\\$\\$\n",
    "sum_other_lex_{COUNTY} equiv sum_{COUNTY_PRE neq COUNTY} LEX\n",
    "\\$\\$\n",
    "\n",
    "This is the sum across all other counties of the portion of devices in\n",
    "“COUNTY” on a given date, appeared in a given other county in the past\n",
    "two weeks. Since a single device can visit multiple counties in the\n",
    "past two weeks, this sum can be greater 1. A bigger number means more\n",
    "devices visited more different counties in the past two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def loadlexdata_aggregate(dates) :\n",
    "     dflist = list()\n",
    "     for day in dates :\n",
    "         print(f\"working on {day}\")\n",
    "         filename = datadir+'/county_lex_' + day.strftime(\"%Y-%m-%d\") + '.csv.gz'\n",
    "         if os.path.isfile(filename):\n",
    "             df = pd.read_csv(filename, compression='gzip', header=0)\n",
    "             df[\"date\"] = day\n",
    "             df = df.melt(id_vars=['COUNTY_PRE','date'], var_name='COUNTY', value_name='LEX')\n",
    "             df[\"COUNTY\"] = df[\"COUNTY\"].astype(int)\n",
    "             own = df.query(\"COUNTY==COUNTY_PRE\").copy()\n",
    "             own.rename(columns={\"LEX\":\"own_lex\"}, inplace=True)\n",
    "             own.drop(columns=\"COUNTY_PRE\", inplace=True)\n",
    "             other = df.query(\"COUNTY!=COUNTY_PRE\").groupby(\"COUNTY\").sum()\n",
    "             other.reset_index(inplace=True)\n",
    "             other.drop(columns=\"COUNTY_PRE\", inplace=True)\n",
    "             other.rename(columns={\"LEX\":\"sum_other_lex\"}, inplace=True)\n",
    "             own=own.merge(other, on=\"COUNTY\")\n",
    "             dflist.append(own)\n",
    "     lexdf = pd.DataFrame().append(dflist)\n",
    "     lexdf.sort_values('date', inplace=True)\n",
    "     return(lexdf)\n",
    "\n",
    "if (False) :\n",
    "    downloadlex(pd.date_range(start, datetime.date.today()))\n",
    "    lex = loadlexdata_aggregate(pd.date_range(start,datetime.date.today()))\n",
    "    lex.to_pickle(\"lex_aggregate.wdi.gz\")\n",
    "else :\n",
    "    url = \"https://github.com/ubcecon/ECON323_2020/blob/master/extra_notebooks/covid-cases.ipynb?raw=true\"\n",
    "    lex = pd.read_pickle(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the code as written only downloads a pre-aggregated cache of\n",
    "data. If you want to rerun the data aggregation code, you should\n",
    "change False to True in the code above.\n",
    "\n",
    "Let’s look at some exploratory figures for the movement index data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lex.plot(\"own_lex\",\"sum_other_lex\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An animated plot showing how the relationship between our two summary\n",
    "measures of movement changes with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def animated_scatter(df, x, y, t):\n",
    "    fig, ax = plt.subplots(2, 1,  gridspec_kw={'height_ratios': [5, 1]})\n",
    "    ts = df[t].unique()\n",
    "    ts.sort()\n",
    "    ax[0].set_xlabel(x)\n",
    "    ax[0].set_ylabel(y)\n",
    "    scat=ax[0].scatter(df[x], df[y])\n",
    "    line,=ax[1].plot(df[t], np.linspace(0,1,len(df[t])))\n",
    "    ax[1].set_xlabel(t)\n",
    "    ax[1].yaxis.set_visible(False)\n",
    "    plt.setp(ax[1].spines.values(), visible=False)\n",
    "\n",
    "\n",
    "    def init():\n",
    "        sdf = df.loc[df[t]==ts[0],:]\n",
    "        scat.set_offsets(np.array(sdf[[x,y]]))\n",
    "        line.set_data([ts[0],ts[0]],[0,1])\n",
    "        return scat,line\n",
    "\n",
    "    def animate(tval):\n",
    "        sdf = df.loc[df[t]==tval,:]\n",
    "        scat.set_offsets(np.array(sdf[[x,y]]))\n",
    "        line.set_data([tval,tval],[0,1])\n",
    "        return scat,line\n",
    "\n",
    "    fig.tight_layout()\n",
    "    anim = FuncAnimation(fig, animate, init_func=init,\n",
    "                         frames=ts, interval=200, blit=True)\n",
    "\n",
    "anim=animated_scatter(lex,\"own_lex\",\"sum_other_lex\", \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, I’m not sure that animation is particularly successful, but it at\n",
    "least illustrates another matplotlib feature.\n",
    "\n",
    "Let’s look at averages over time. So that both movement measures\n",
    "increase with more movement, let’s define “new_visits” = 1 - “own_lex”\n",
    "and look at that instead of “own_lex”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "colors = qeds.themes.COLOR_CYCLE\n",
    "lex[\"new_visits\"] = 1 - lex[\"own_lex\"]\n",
    "avg=lex.groupby(\"date\").mean().reset_index()\n",
    "avg.plot(\"date\",\"new_visits\", ax=ax[0], color=colors[0])\n",
    "avg.plot(\"date\",\"sum_other_lex\", ax=ax[1], color=colors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some cyclicality related to weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "\n",
    "To further explore the data, let’s map it. We’ll use plotly.express\n",
    "for mapping this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# download some map data\n",
    "import plotly.express as px\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a map of current cases in each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# get only the most recent day\n",
    "covid = covid.sort_values(by='Date')\n",
    "df = covid.drop_duplicates('FIPS', keep='last')\n",
    "\n",
    "df[\"log10cases\"] = np.log10(df[\"cases\"]+0.01)\n",
    "\n",
    "fig = px.choropleth(df, geojson=counties, locations='FIPS', color='log10cases',\n",
    "                    color_continuous_scale=\"thermal\",\n",
    "                    range_color=(0, df['log10cases'].max()),\n",
    "                    scope=\"usa\",\n",
    "                    labels={'log10cases':'log10(cases)'},\n",
    "                    hover_name=\"Admin2\",\n",
    "                    hover_data=[\"cases\",\"deaths\"],\n",
    "                    title=f\"Confirmed cases as of {df.Date.max().strftime('%Y-%m-%d')}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that county level data is missing from a few states.\n",
    "\n",
    "A map of movement indices. First from January 20th (the earliest date available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# get only the most recent day\n",
    "df = lex.drop_duplicates('COUNTY', keep='first')\n",
    "\n",
    "fig = px.choropleth(df, geojson=counties, locations='COUNTY', color='sum_other_lex',\n",
    "                    color_continuous_scale=\"Viridis\",\n",
    "                    #range_color=(0, df['log10cases'].max()),\n",
    "                    scope=\"usa\",\n",
    "                    #labels={'log10cases':'log10(cases)'},\n",
    "                    hover_name=\"COUNTY\",\n",
    "                    hover_data=[\"sum_other_lex\", \"own_lex\"],\n",
    "                    title=f\"Index of movement across counties on {df.date[1].strftime('%Y-%m-%d')}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# get only the most recent day\n",
    "df = lex.drop_duplicates('COUNTY', keep='last')\n",
    "\n",
    "fig = px.choropleth(df, geojson=counties, locations='COUNTY', color='sum_other_lex',\n",
    "                    color_continuous_scale=\"Viridis\",\n",
    "                    #range_color=(0, df['log10cases'].max()),\n",
    "                    scope=\"usa\",\n",
    "                    #labels={'log10cases':'log10(cases)'},\n",
    "                    hover_name=\"COUNTY\",\n",
    "                    hover_data=[\"sum_other_lex\",\"own_lex\"],\n",
    "                    title=f\"Index of movement across counties on {df.date[1].strftime('%Y-%m-%d')}\")                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between mobility and cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lex = lex.merge(covid, left_on=[\"COUNTY\", \"date\"], right_on=[\"FIPS\",\"Date\"], how=\"outer\");\n",
    "\n",
    "# we only need a single county and date variable. Drop the extra to avoid confusion\n",
    "ms=pd.isna(lex[\"Date\"])\n",
    "lex.loc[ms,\"Date\"] = lex.loc[ms, \"date\"]\n",
    "lex = lex.drop(columns=\"date\")\n",
    "ms=pd.isna(lex[\"FIPS\"])\n",
    "lex.loc[ms,\"FIPS\"] = lex.loc[ms, \"COUNTY\"]\n",
    "lex = lex.drop(colums=\"COUNTY\")\n",
    "lex[\"FIPS\"]=lex[\"FIPS\"].map(lambda x: \"{:05.0f}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now explore the relationship betwen mobility and cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "colors = qeds.themes.COLOR_CYCLE\n",
    "markersize=1\n",
    "ax[0].scatter(lex.new_visits, np.log10((lex.cases+0.9)), color=colors[0], s=markersize)\n",
    "ax[0].set_ylabel(\"log_10(cases)\")\n",
    "ax[0].set_xlabel(\"new visit index\")\n",
    "ax[1].scatter(lex.sum_other_lex, np.log10((lex.cases+0.9)), color=colors[1], s=markersize)\n",
    "ax[1].set_ylabel(\"log_10(cases)\")\n",
    "ax[1].set_xlabel(\"sum other lex\")\n",
    "fig.suptitle(\"Movement indices and cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, it appears that there’s a *negative* relationship between\n",
    "movement and cases.  However, this plot includes all dates. It is\n",
    "combining the upward trend in cases and downward trend in movement\n",
    "with whatever the cross-sectional relationship between cases and\n",
    "movement on a given date might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lex[\"log10cases\"] = np.log(lex[\"cases\"]+0.9)\n",
    "anim=animated_scatter(lex,\"new_visits\",\"log10cases\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "anim=animated_scatter(lex,\"sum_other_lex\",\"log10cases\",\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that even conditional on date, there remains a\n",
    "negative correlation between these movement indices and county. This\n",
    "is a bit puzzling. There are two important confounding factors.\n",
    "\n",
    "One is that most measures of movement, including these, are negatively\n",
    "correlated with population density. People in dense cities rarely have\n",
    "to cross county boundaries to go shopping or to work. People in rural\n",
    "areas often do. Density will tend to be positively related to case\n",
    "numbers.\n",
    "\n",
    "The second confounder is that since there is some delay between\n",
    "infections occurring and them showing up in confirmed case numbers, we\n",
    "should expect not current movement, but past movement to increase\n",
    "current case numbers.\n",
    "\n",
    "Related to the second point, we can see in these animations that the\n",
    "points tend to drift up and left. As current confirmed cases increase,\n",
    "movement tends to decrease.\n",
    "\n",
    "Thus, if we want to use this movement data to predict cases, we should :\n",
    "\n",
    "1. Control for density and perhaps other county characteristics.  \n",
    "1. Look at lagged movement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County Population Density\n",
    "\n",
    "We download data on county area and population from the US Census Bureau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt># download county population data</dt>\n",
    "<dd>\n",
    "import wget\n",
    "filename = “co-est2019-alldata.csv”\n",
    "if not os.path.isfile(filename) :\n",
    "\n",
    "> url = “[https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv)”\n",
    "wget.download(url, filename)\n",
    "\n",
    "\n",
    "cpop=pd.read_csv(filename, encoding=”iso-8859-1”)\n",
    "\n",
    "\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt>cpop[“countyFIPS”] = (cpop[“STATE”].map(lambda x: “{:02d}”.format(x)) +</dt>\n",
    "<dd>\n",
    "cpop[“COUNTY”].map(lambda x: “{:03d}”.format(x)))\n",
    "\n",
    "</dd>\n",
    "\n",
    "</dl>\n",
    "\n",
    "cpop[“population”] = cpop[“POPESTIMATE2019”]\n",
    "\n",
    "# get county areas\n",
    "import geopandas as gpd\n",
    "areas = gpd.read_file(“[http://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_us_county_5m.zip](http://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_us_county_5m.zip)”)\n",
    "cpop = cpop.merge(areas,left_on=”countyFIPS”, right_on=”GEOID”, how=”outer”, validate=”1:1”)\n",
    "cpop[“density”] = cpop[“population”]/cpop[“ALAND”]*1000*1000\n",
    "\n",
    "\n",
    "<dl style='margin: 20px 0;'>\n",
    "<dt>lex=lex.merge(cpop[[“countyFIPS”,”density”,”population”,”ALAND”]],</dt>\n",
    "<dd>\n",
    "left_on=”FIPS”, right_on=”countyFIPS”, how=”left”);\n",
    "\n",
    "</dd>\n",
    "\n",
    "</dl>\n",
    "\n",
    "import seaborn as sns\n",
    "lex[“logdensity”] = np.log10(lex[“density”])\n",
    "sns.pairplot(lex, vars=[“log10cases”, “new_visits”, “sum_other_lex”, “logdensity”])\n",
    "\n",
    "</dd>\n",
    "\n",
    "</dl>\n",
    "\n",
    "From the last column we see that density is positively correlated with\n",
    "cases and negatively correlated with movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions\n",
    "\n",
    "We will use regression to examine the relationship between cases and\n",
    "movement conditional on density.\n",
    "\n",
    "The delay between infection and showing in case numbers is uncertain,\n",
    "so will regress case growth on many lags of our movement measures. To\n",
    "reduce colinearity, and to eliminate the weekly cyclicality in\n",
    "movement, we’ll create weekly sums of the movement indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lex.set_index([\"FIPS\",\"Date\"], inplace=True)\n",
    "\n",
    "# predict growth rate in cases\n",
    "y = lex[\"log10cases\"] - lex.groupby(\"FIPS\")[\"log10cases\"].shift(1)\n",
    "def createx(lags, vars=[\"new_visits\",\"sum_other_lex\"]):\n",
    "    X = lex[[\"logdensity\"]].copy()\n",
    "    X[\"constant\"] = 1\n",
    "    t0=lex.reset_index()[\"Date\"].min()\n",
    "    X[\"t\"] = np.array((lex.reset_index()[\"Date\"]-t0).dt.days)\n",
    "    X[\"log10casesL1\"]=lex.groupby(\"FIPS\")[\"log10cases\"].shift(1)\n",
    "    for l in lags:\n",
    "        week, day = np.divmod(l,7)\n",
    "        for v in vars:\n",
    "            if day==0 :\n",
    "                X[\"{}LW{:02d}\".format(v,week)] = lex.groupby(\"FIPS\")[v].shift(l)\n",
    "            else :\n",
    "                X[\"{}LW{:02d}\".format(v,week)] = (X[\"{}LW{:02d}\".format(v,week)] +\n",
    "                                                   lex.groupby(\"FIPS\")[v].shift(l))\n",
    "    return(X)\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "X = createx(range(7,36), vars=[\"sum_other_lex\"])\n",
    "reg=sm.OLS(y, X, missing='drop').fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X = createx(range(7,36), vars=[\"new_visits\"])\n",
    "reg=sm.OLS(y, X, missing='drop').fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With either measure, it appears that movement in “lag week 3”, which\n",
    "corresponds to 21-27 days ago has a strong positive relationship with\n",
    "current case growth."
   ]
  }
 ],
 "metadata": {
  "date": 1586377613.4740071,
  "filename": "covid-movement.rst",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Covid Spread and Movement"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}